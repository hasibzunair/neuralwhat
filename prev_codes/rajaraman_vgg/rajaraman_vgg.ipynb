{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rajaraman_vgg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tiEV3cHhSQ5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import cv2\n",
        "import random\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.utils import class_weight\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import average_precision_score\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
        "from keras.layers import Conv2D, Activation, Dense, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOd7fODrVyra",
        "colab_type": "code",
        "outputId": "a3765a95-ba59-466f-bdfd-dc490aa25f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwaLEhTcSW61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qsoVbwN9UVNE",
        "colab_type": "code",
        "outputId": "87fa56c4-87be-4317-af40-4625948df7d7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98abc2bb-f7ab-4ae6-ad48-5de711cc64fe\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-98abc2bb-f7ab-4ae6-ad48-5de711cc64fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 67 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cUuuu_vrWAQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "riPFNpayXg76",
        "colab_type": "code",
        "outputId": "296d2b95-8ca0-4f22-d4e2-14528a7d5a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hasibzunair/malaria"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading malaria.zip to /content\n",
            "100% 811M/815M [00:10<00:00, 92.5MB/s]\n",
            "100% 815M/815M [00:10<00:00, 80.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w4GI7_AIYh7o",
        "colab_type": "code",
        "outputId": "98d528d0-a6d1-4669-a23e-ac18b27ec2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip 'malaria.zip'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  malaria.zip\n",
            "  inflating: y_test.npy              \n",
            "  inflating: x_test.npy              \n",
            "  inflating: y_train.npy             \n",
            "  inflating: y_val.npy               \n",
            "  inflating: x_train.npy             \n",
            "  inflating: x_val.npy               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vNtyCkIPYjKy",
        "colab_type": "code",
        "outputId": "5f0f258f-43e2-4aec-8f6f-4785893d6010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_data  x_train.npy  y_test.npy   y_val.npy\n",
            "malaria.zip  x_test.npy   x_val.npy    y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7YEH44-4pjyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x_train = np.load(\"x_train.npy\")\n",
        "#y_train = np.load(\"y_train.npy\")\n",
        "#x_train.shape, y_train.shape\n",
        "#x_val = np.load(\"x_val.npy\")\n",
        "#y_val = np.load(\"y_val.npy\")\n",
        "#x_val.shape, y_val.shape\n",
        "#x_test = np.load(\"x_test.npy\")\n",
        "#y_test = np.load(\"y_test.npy\")\n",
        "#x_test.shape, y_test.shape\n",
        "#print(x_train.shape, y_train.shape)\n",
        "#print(x_val.shape, x_test.shape, y_val.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zr0uBPoToDLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_train_samples = 22046 #  modify for your dataset\n",
        "nb_valid_samples = 2756 #  modify for your dataset\n",
        "nb_test_samples = 2756 # modify for your dataset\n",
        "num_classes = 2 # binary classification "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7Llq3Cim4D9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False, #if true all values in confusion matrix is between 0 and 1\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZq77LbMm6Xn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_resized_training_data(img_rows, img_cols):\n",
        "\n",
        "    X_train = np.load(\"x_train.npy\")\n",
        "    Y_train = np.load(\"y_train.npy\")\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
        "    \n",
        "    return X_train, Y_train\n",
        "    \n",
        "def load_resized_validation_data(img_rows, img_cols):\n",
        "\n",
        "    X_valid = np.load(\"x_val.npy\")\n",
        "    Y_valid = np.load(\"y_val.npy\")\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
        "        \n",
        "    return X_valid, Y_valid   \n",
        "\n",
        "def load_resized_test_data(img_rows, img_cols):\n",
        "\n",
        "    X_test = np.load(\"x_test.npy\")\n",
        "    Y_test = np.load(\"y_test.npy\")\n",
        "    X_test = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_test[:nb_test_samples,:,:,:]])\n",
        "    \n",
        "    return X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9WTMhnrnoMr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows=224 #dimensions of image required for VGG16\n",
        "img_cols=224\n",
        "channel = 3 #RGB\n",
        "batch_size = 32 # modify based on the GPUs in your system\n",
        "num_epoch = 100 # modify depending on the model's convergence with your data\n",
        "\n",
        "#load data\n",
        "X_train, Y_train = load_resized_training_data(img_rows, img_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7XgkZODnsYe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_valid, Y_valid = load_resized_validation_data(img_rows, img_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a9PNC9Qansf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test, Y_test = load_resized_test_data(img_rows, img_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tA27z3XnzNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "15d646b3-ed6c-430d-b26c-24c24b683bf8"
      },
      "cell_type": "code",
      "source": [
        "#print the shape of the data\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_valid.shape, Y_valid.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22046, 224, 224, 3) (22046, 2)\n",
            "(2756, 224, 224, 3) (2756, 2)\n",
            "(2756, 224, 224, 3) (2756, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gHYInTAGqb11",
        "outputId": "71a1a5f9-a4e7-4b23-a11c-a45af980cd64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = x_train.shape[1]\n",
        "IMAGE_SIZE"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "cJA_ensDpYUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "a7c01dbc-aa66-405a-af90-624eae3bceea"
      },
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, channel))\n",
        "\n",
        "#extract feature from the optimal layer for your data\n",
        "base_model = Model(input=base_model.input, output=base_model.get_layer('block5_conv2').output) \n",
        "\n",
        "#get the model summary\n",
        "base_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "=================================================================\n",
            "Total params: 12,354,880\n",
            "Trainable params: 12,354,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s_4bSEnPpkOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets modify the architecture by adding a global spatial average pooling layer and a fully-connected layer with a dropout ratio of 0.5 to prevent overfitting and help model generalization. We will train only the top layers which are randomly initialized, freeze all the convolutional layers to prevent large gradient updates wrecking the learned weights."
      ]
    },
    {
      "metadata": {
        "id": "yMMyJQiepYXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "8e0f79a5-64c7-4774-99b2-a53ce8af76f8"
      },
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional layers to prevent large gradient updates wrecking the learned weights\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#fix the optimizer\n",
        "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True) \n",
        "\n",
        "#compile the model\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"The final model...\")\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The final model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 12,882,242\n",
            "Trainable params: 527,362\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WE_jjLfKqhMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a4536c0-ab3e-4f21-dd93-4abb7642f93f"
      },
      "cell_type": "code",
      "source": [
        "model.name"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "4ZqXHwe37gRF",
        "colab_type": "code",
        "outputId": "539fb9d8-57b3-407a-bad0-7326d59a0110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check input\n",
        "print(X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22046, 224, 224, 3) (22046, 2) (2756, 224, 224, 3) (2756, 2) (2756, 224, 224, 3) (2756, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZDzM1zb5rLFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mkdir weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hQ6YqTRgt6im",
        "colab_type": "code",
        "outputId": "a5f62eb9-589b-4f40-8265-a7220a10bb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_data  x_test.npy   x_val.npy   y_train.npy\n",
            "malaria.zip  weights\t  x_train.npy  y_test.npy  y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uUTy2tgnstHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -f \"vgg_1a.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y4ikeUhUgKp0",
        "colab_type": "code",
        "outputId": "317beb6e-0391-407b-afa2-af03fbcf711f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6043
        }
      },
      "cell_type": "code",
      "source": [
        "#model=vgg16()\n",
        "#path_model='vgg_1a.h5'  \n",
        "\n",
        "filepath = 'weights/' + model.name + '.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
        "                             save_weights_only=True, save_best_only=True, mode='max', period=1)\n",
        "\n",
        "#tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#compute training time\n",
        "t=time.time()\n",
        "hist = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                 callbacks=callbacks_list,\n",
        "                 epochs=num_epoch, verbose=1, \n",
        "                 shuffle=True, validation_data=[X_valid, Y_valid])\n",
        "\n",
        "#compute the training time\n",
        "print('Training time: %s' % (time.time()-t))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 22046 samples, validate on 2756 samples\n",
            "Epoch 1/100\n",
            "22046/22046 [==============================] - 238s 11ms/step - loss: 1.4578 - acc: 0.7672 - val_loss: 0.2578 - val_acc: 0.9401\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.94013, saving model to weights/model_4.01-0.9401.hdf5\n",
            "Epoch 2/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.4897 - acc: 0.8806 - val_loss: 0.2063 - val_acc: 0.9470\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.94013 to 0.94702, saving model to weights/model_4.02-0.9470.hdf5\n",
            "Epoch 3/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.3333 - acc: 0.9042 - val_loss: 0.1792 - val_acc: 0.9492\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.94702 to 0.94920, saving model to weights/model_4.03-0.9492.hdf5\n",
            "Epoch 4/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.2709 - acc: 0.9164 - val_loss: 0.1686 - val_acc: 0.9481\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.94920\n",
            "Epoch 5/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.2429 - acc: 0.9215 - val_loss: 0.1590 - val_acc: 0.9499\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.94920 to 0.94993, saving model to weights/model_4.05-0.9499.hdf5\n",
            "Epoch 6/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.2270 - acc: 0.9231 - val_loss: 0.1581 - val_acc: 0.9478\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.94993\n",
            "Epoch 7/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.2121 - acc: 0.9290 - val_loss: 0.1514 - val_acc: 0.9528\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.94993 to 0.95283, saving model to weights/model_4.07-0.9528.hdf5\n",
            "Epoch 8/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.2064 - acc: 0.9305 - val_loss: 0.1535 - val_acc: 0.9492\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.95283\n",
            "Epoch 9/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1939 - acc: 0.9323 - val_loss: 0.1466 - val_acc: 0.9543\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.95283 to 0.95428, saving model to weights/model_4.09-0.9543.hdf5\n",
            "Epoch 10/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1909 - acc: 0.9344 - val_loss: 0.1471 - val_acc: 0.9557\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.95428 to 0.95573, saving model to weights/model_4.10-0.9557.hdf5\n",
            "Epoch 11/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1860 - acc: 0.9364 - val_loss: 0.1446 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.95573\n",
            "Epoch 12/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1828 - acc: 0.9368 - val_loss: 0.1467 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.95573\n",
            "Epoch 13/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1790 - acc: 0.9392 - val_loss: 0.1425 - val_acc: 0.9539\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.95573\n",
            "Epoch 14/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1754 - acc: 0.9400 - val_loss: 0.1414 - val_acc: 0.9572\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.95573 to 0.95718, saving model to weights/model_4.14-0.9572.hdf5\n",
            "Epoch 15/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1736 - acc: 0.9399 - val_loss: 0.1454 - val_acc: 0.9517\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.95718\n",
            "Epoch 16/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1700 - acc: 0.9414 - val_loss: 0.1495 - val_acc: 0.9488\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.95718\n",
            "Epoch 17/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1727 - acc: 0.9399 - val_loss: 0.1398 - val_acc: 0.9565\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.95718\n",
            "Epoch 18/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1723 - acc: 0.9407 - val_loss: 0.1396 - val_acc: 0.9536\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.95718\n",
            "Epoch 19/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1686 - acc: 0.9412 - val_loss: 0.1367 - val_acc: 0.9583\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.95718 to 0.95827, saving model to weights/model_4.19-0.9583.hdf5\n",
            "Epoch 20/100\n",
            "22046/22046 [==============================] - 227s 10ms/step - loss: 0.1653 - acc: 0.9412 - val_loss: 0.1365 - val_acc: 0.9579\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.95827\n",
            "Epoch 21/100\n",
            "22046/22046 [==============================] - 227s 10ms/step - loss: 0.1650 - acc: 0.9433 - val_loss: 0.1353 - val_acc: 0.9557\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.95827\n",
            "Epoch 22/100\n",
            "22046/22046 [==============================] - 227s 10ms/step - loss: 0.1655 - acc: 0.9439 - val_loss: 0.1354 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.95827 to 0.95900, saving model to weights/model_4.22-0.9590.hdf5\n",
            "Epoch 23/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1616 - acc: 0.9434 - val_loss: 0.1348 - val_acc: 0.9554\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.95900\n",
            "Epoch 24/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1622 - acc: 0.9442 - val_loss: 0.1355 - val_acc: 0.9579\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.95900\n",
            "Epoch 25/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1633 - acc: 0.9436 - val_loss: 0.1364 - val_acc: 0.9586\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.95900\n",
            "Epoch 26/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1593 - acc: 0.9465 - val_loss: 0.1366 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.95900 to 0.95936, saving model to weights/model_4.26-0.9594.hdf5\n",
            "Epoch 27/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1593 - acc: 0.9438 - val_loss: 0.1344 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.95936\n",
            "Epoch 28/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1575 - acc: 0.9460 - val_loss: 0.1335 - val_acc: 0.9583\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.95936\n",
            "Epoch 29/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1585 - acc: 0.9453 - val_loss: 0.1333 - val_acc: 0.9597\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.95936 to 0.95972, saving model to weights/model_4.29-0.9597.hdf5\n",
            "Epoch 30/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1545 - acc: 0.9472 - val_loss: 0.1324 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.95972\n",
            "Epoch 31/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1553 - acc: 0.9467 - val_loss: 0.1323 - val_acc: 0.9579\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.95972\n",
            "Epoch 32/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1555 - acc: 0.9472 - val_loss: 0.1310 - val_acc: 0.9561\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.95972\n",
            "Epoch 33/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1538 - acc: 0.9467 - val_loss: 0.1311 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.95972\n",
            "Epoch 34/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1526 - acc: 0.9475 - val_loss: 0.1353 - val_acc: 0.9583\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.95972\n",
            "Epoch 35/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1533 - acc: 0.9441 - val_loss: 0.1306 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.95972\n",
            "Epoch 36/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1535 - acc: 0.9466 - val_loss: 0.1304 - val_acc: 0.9619\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.95972 to 0.96190, saving model to weights/model_4.36-0.9619.hdf5\n",
            "Epoch 37/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1520 - acc: 0.9467 - val_loss: 0.1312 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.96190\n",
            "Epoch 38/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1461 - acc: 0.9506 - val_loss: 0.1285 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.96190\n",
            "Epoch 39/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1489 - acc: 0.9483 - val_loss: 0.1294 - val_acc: 0.9604\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.96190\n",
            "Epoch 40/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1473 - acc: 0.9493 - val_loss: 0.1291 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.96190\n",
            "Epoch 41/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1477 - acc: 0.9495 - val_loss: 0.1306 - val_acc: 0.9565\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.96190\n",
            "Epoch 42/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1485 - acc: 0.9482 - val_loss: 0.1293 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.96190\n",
            "Epoch 43/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1454 - acc: 0.9495 - val_loss: 0.1296 - val_acc: 0.9586\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.96190\n",
            "Epoch 44/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1433 - acc: 0.9519 - val_loss: 0.1317 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.96190\n",
            "Epoch 45/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1452 - acc: 0.9500 - val_loss: 0.1281 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.96190\n",
            "Epoch 46/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1457 - acc: 0.9487 - val_loss: 0.1291 - val_acc: 0.9572\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.96190\n",
            "Epoch 47/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1447 - acc: 0.9489 - val_loss: 0.1283 - val_acc: 0.9597\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.96190\n",
            "Epoch 48/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1465 - acc: 0.9492 - val_loss: 0.1286 - val_acc: 0.9568\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.96190\n",
            "Epoch 49/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1423 - acc: 0.9499 - val_loss: 0.1268 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.96190\n",
            "Epoch 50/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1428 - acc: 0.9503 - val_loss: 0.1267 - val_acc: 0.9604\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.96190\n",
            "Epoch 51/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1413 - acc: 0.9500 - val_loss: 0.1412 - val_acc: 0.9514\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.96190\n",
            "Epoch 52/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1429 - acc: 0.9499 - val_loss: 0.1263 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.96190\n",
            "Epoch 53/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1396 - acc: 0.9500 - val_loss: 0.1267 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.96190\n",
            "Epoch 54/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1418 - acc: 0.9506 - val_loss: 0.1267 - val_acc: 0.9612\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.96190\n",
            "Epoch 55/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1407 - acc: 0.9516 - val_loss: 0.1284 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.96190\n",
            "Epoch 56/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1428 - acc: 0.9509 - val_loss: 0.1263 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.96190\n",
            "Epoch 57/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1393 - acc: 0.9500 - val_loss: 0.1263 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.96190\n",
            "Epoch 58/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1382 - acc: 0.9524 - val_loss: 0.1258 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.96190\n",
            "Epoch 59/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1388 - acc: 0.9516 - val_loss: 0.1269 - val_acc: 0.9579\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.96190\n",
            "Epoch 60/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1391 - acc: 0.9523 - val_loss: 0.1250 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.96190\n",
            "Epoch 61/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1398 - acc: 0.9518 - val_loss: 0.1275 - val_acc: 0.9630\n",
            "\n",
            "Epoch 00061: val_acc improved from 0.96190 to 0.96299, saving model to weights/model_4.61-0.9630.hdf5\n",
            "Epoch 62/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1370 - acc: 0.9516 - val_loss: 0.1255 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.96299\n",
            "Epoch 63/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1385 - acc: 0.9516 - val_loss: 0.1265 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.96299\n",
            "Epoch 64/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1383 - acc: 0.9510 - val_loss: 0.1290 - val_acc: 0.9612\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.96299\n",
            "Epoch 65/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1380 - acc: 0.9522 - val_loss: 0.1253 - val_acc: 0.9626\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.96299\n",
            "Epoch 66/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1367 - acc: 0.9511 - val_loss: 0.1249 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.96299\n",
            "Epoch 67/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1361 - acc: 0.9523 - val_loss: 0.1245 - val_acc: 0.9626\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.96299\n",
            "Epoch 68/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1366 - acc: 0.9516 - val_loss: 0.1246 - val_acc: 0.9623\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.96299\n",
            "Epoch 69/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1365 - acc: 0.9517 - val_loss: 0.1240 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.96299\n",
            "Epoch 70/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1359 - acc: 0.9531 - val_loss: 0.1296 - val_acc: 0.9557\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.96299\n",
            "Epoch 71/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1375 - acc: 0.9518 - val_loss: 0.1241 - val_acc: 0.9597\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.96299\n",
            "Epoch 72/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1352 - acc: 0.9529 - val_loss: 0.1232 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.96299\n",
            "Epoch 73/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1365 - acc: 0.9522 - val_loss: 0.1223 - val_acc: 0.9619\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.96299\n",
            "Epoch 74/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1360 - acc: 0.9519 - val_loss: 0.1235 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.96299\n",
            "Epoch 75/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1345 - acc: 0.9531 - val_loss: 0.1248 - val_acc: 0.9630\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.96299\n",
            "Epoch 76/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1348 - acc: 0.9529 - val_loss: 0.1238 - val_acc: 0.9604\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.96299\n",
            "Epoch 77/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1352 - acc: 0.9532 - val_loss: 0.1222 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.96299\n",
            "Epoch 78/100\n",
            "22046/22046 [==============================] - 229s 10ms/step - loss: 0.1341 - acc: 0.9533 - val_loss: 0.1223 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.96299\n",
            "Epoch 79/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1324 - acc: 0.9535 - val_loss: 0.1231 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.96299\n",
            "Epoch 80/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1343 - acc: 0.9536 - val_loss: 0.1225 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.96299\n",
            "Epoch 81/100\n",
            "22046/22046 [==============================] - 230s 10ms/step - loss: 0.1315 - acc: 0.9529 - val_loss: 0.1213 - val_acc: 0.9619\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.96299\n",
            "Epoch 82/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1319 - acc: 0.9542 - val_loss: 0.1249 - val_acc: 0.9634\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.96299 to 0.96335, saving model to weights/model_4.82-0.9634.hdf5\n",
            "Epoch 83/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1306 - acc: 0.9538 - val_loss: 0.1213 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.96335\n",
            "Epoch 84/100\n",
            "22046/22046 [==============================] - 228s 10ms/step - loss: 0.1303 - acc: 0.9553 - val_loss: 0.1213 - val_acc: 0.9619\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.96335\n",
            "Epoch 85/100\n",
            "21952/22046 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9539Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2qN7ElfhH0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['acc']\n",
        "val_acc=hist.history['val_acc']\n",
        "xc=range(num_epoch)\n",
        "\n",
        "plt.figure(1,figsize=(20,10), dpi=100)\n",
        "plt.plot(xc,train_loss)\n",
        "plt.plot(xc,val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.figure(2,figsize=(20,10), dpi=100)\n",
        "plt.plot(xc,train_acc)\n",
        "plt.plot(xc,val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "plt.style.use(['classic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5IQUSlp3rnOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.load_weights('weights/model_2.01-0.8546.hdf5') #modify for your own model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6z-ycnmqUbv",
        "colab_type": "code",
        "outputId": "9c7ab341-05b4-4cf7-90e7-8ba4b999cd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# compute the accuracy\n",
        "Test_accuracy = accuracy_score(Y_test.argmax(axis=-1),y_pred.argmax(axis=-1))\n",
        "print(\"Test_Accuracy = \",Test_accuracy)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2756/2756 [==============================] - 25s 9ms/step\n",
            "Test_Accuracy =  0.9506531204644412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MRheIRkc7N3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d015f03e-3019-460e-aa2f-1715a7f73083"
      },
      "cell_type": "code",
      "source": [
        "Test_accuracy"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9506531204644412"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "I8BVM7k8glUP",
        "colab_type": "code",
        "outputId": "62d12cf9-9677-4a3a-e124-1b4cdbfcf04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    \n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "#Plot ROC curves\n",
        "plt.figure(figsize=(12,12), dpi=100)\n",
        "lw = 1\n",
        "plt.plot(fpr[1], tpr[1], color='red',\n",
        "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
        "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristics')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# computhe the cross-entropy loss score\n",
        "score = log_loss(Y_test,y_pred)\n",
        "print(score)\n",
        "\n",
        "# compute the average precision score\n",
        "prec_score = average_precision_score(Y_test,y_pred)  \n",
        "print(prec_score)\n",
        "\n",
        "# transfer it back\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "Y_test = np.argmax(Y_test, axis=1)\n",
        "print(y_pred)\n",
        "print(Y_test)\n",
        "\n",
        "#save the predictions as a CSV file for further analysis\n",
        "#np.savetxt('custom_model_y_pred.csv',y_pred,fmt='%i',delimiter = \",\")\n",
        "#np.savetxt('custom_model_Y_test.csv',Y_test,fmt='%i',delimiter = \",\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-cf82d4553024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "myX07oD57d3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c39385ca-790d-40e2-83b3-4f8ae5c788d7"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "custom_model_y_pred.csv  malaria.zip  x_test.npy   y_test.npy\n",
            "custom_model_Y_test.csv  sample_data  x_train.npy  y_train.npy\n",
            "kaggle.json\t\t weights      x_val.npy    y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UfKrus_Gr2Kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1645
        },
        "outputId": "ea106193-5c82-4497-d58d-a4b65f1cdd9a"
      },
      "cell_type": "code",
      "source": [
        "target_names = ['class 0(abnormal)', 'class 1(normal)'] #decide the labels for your own data\n",
        "print(classification_report(Y_test,y_pred,target_names=target_names))\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "cnf_matrix = (confusion_matrix(Y_test,y_pred))\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(14,14), dpi=100)\n",
        "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
        "                  title='Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "class 0(abnormal)       0.95      0.95      0.95      1409\n",
            "  class 1(normal)       0.95      0.95      0.95      1347\n",
            "\n",
            "        micro avg       0.95      0.95      0.95      2756\n",
            "        macro avg       0.95      0.95      0.95      2756\n",
            "     weighted avg       0.95      0.95      0.95      2756\n",
            "\n",
            "[[1343   66]\n",
            " [  70 1277]]\n",
            "Confusion matrix, without normalization\n",
            "[[1343   66]\n",
            " [  70 1277]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABS0AAAVkCAYAAAAxIjrbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQKEILQEAAACAQhFaAgAAAACF8n/R76HV7nHIrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1400x1400 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mUbgYhXgmyEi",
        "colab_type": "code",
        "outputId": "856a04fb-d8e0-46a4-c42c-8d2d2cf6f8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory files: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P6Bj_sKdmyK1",
        "colab_type": "code",
        "outputId": "6b074d94-e50d-4d0c-cddc-a7ec5cdff288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files\t     malaria.zip  vgg_1a.h5   x_train.npy  y_test.npy\ty_val.npy\n",
            "kaggle.json  sample_data  x_test.npy  x_val.npy    y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SrRehrb4mRDk",
        "colab_type": "code",
        "outputId": "9320116d-0337-40df-e673-8c8bcda7de64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#pred_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2756,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "3fj7_it8mRPX",
        "colab_type": "code",
        "outputId": "a6a947b4-6450-4e2d-8d23-3797a707349e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#!cp pred_labels.npy files\n",
        "#!cp vgg_1a.h5 files\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'pred_labels.npy': No such file or directory\n",
            "cp: cannot stat 'vgg_1a.h5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rWO1Q6Tl-dX",
        "colab_type": "code",
        "outputId": "5d52b0a3-6263-4aa2-9a22-a39ca746b307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# zip folder\n",
        "#!zip -r files.zip files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: files/ (stored 0%)\n",
            "  adding: files/pred_labels.npy (deflated 96%)\n",
            "  adding: files/vgg_1a.h5 (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sXq4KVlPw8v9",
        "colab_type": "code",
        "outputId": "58556963-78d2-4f69-d45f-221b7c9951c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files\t   kaggle.json\tsample_data  x_train.npy  y_test.npy   y_val.npy\n",
            "files.zip  malaria.zip\tx_test.npy   x_val.npy\t  y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ABOnul_WxkaP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('files.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZ-HCWX3xxs5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}